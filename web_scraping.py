# -*- coding: utf-8 -*-
"""web scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dgxzkucDFYJ-CWafafzTBdEmuZK098VJ
"""

!pip install requests

!pip install requests beautifulsoup4

import requests
web = requests.get("https://www.tutorialsfreak.com/")
print(web)

web.content

web.url

web.status_code

import requests
from bs4 import BeautifulSoup
web = requests.get("https://www.tutorialsfreak.com/")

web.content

soup = BeautifulSoup(web.content,"html.parser")
print(soup.prettify())

soup.title

soup.title.name

soup.p

soup.a

soup.h1

tag = soup.html

type(tag)

tag = soup.a
tag

"""NavigableString"""

tag = soup.p.string
 tag

tag = soup.a.string
tag

tag = soup.h1.string
tag

"""Beautiful Soup

"""

soup.name

soup.title

soup.head

soup.find ("h1")

soup.find_all("p")

"""commets

"""

class_data = soup.find("div",class_ = "container")

class_data.find_all("p")

lines = soup.find_all('p')

lines

for l in lines:
  print(l.text)

s = soup.find("h3",class_= "fs-20 lh-30 fw-600 label-color-5")
s.text

soup.find_all("a")

for i in soup.find_all("a"):
  print(i.get("href"))

img = soup.find_all("img")

img

for i in img:
  print(i.get("src"))

  print(type(i.get("src")))

for i in img:
  print(i.get("alt"))

url = "https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfPMN/denovo.cfm"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Accept-Encoding": "gzip, deflate, br",
}

r = requests.get(url,headers=headers)
print(r)

soup = BeautifulSoup(r.text,"lxml")
print(soup)

soup.find_all("a")

for i in soup.find_all("a"):
  print(i.get("href"))

soup.find_all("img")

for i in soup.find_all("img"):
  print(i.get("src"))

soup = BeautifulSoup(r.content,"html.parser")
print(soup.prettify())

s = soup.find("div",class_= "pmn-intro")
s.text

s = soup.find("div",class_= "address")
s.text

images=[]
descripitions=[]


url="https://www.fda.gov/about-fda/center-devices-and-radiological-health/cdrh-foia-how-get-records-cdrh"


headers = {
    "User-Agent": "Mozilla/5.0",
    "Accept": "application/json",
}

r=requests.get(url,headers=headers)
soup=BeautifulSoup(r.text,"lxml")
# print(soup)

header1=soup.find_all("h1",id="topic_page_title")
for i in header1:
    headers.append(i.text)

descripition=soup.find_all("p")
for j in descripition:
    descripitions.append(j.text)

img=soup.find_all("img")
for k in img:
    img=images.append(k.get("src"))

print(f"The images links is here {images}")